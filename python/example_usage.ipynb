{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.bedrock import BedrockChatCompletion\n",
    "from semantic_kernel.connectors.ai.bedrock.bedrock_prompt_execution_settings import \\\n",
    "    BedrockChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import \\\n",
    "    FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "\n",
    "from semantic_kernel_plugins.plugins.python.python_code_generator import \\\n",
    "    PythonCodeGeneratorPlugin\n",
    "from semantic_kernel_plugins.plugins.web.tavily_web_search import \\\n",
    "    TavilySearchPlugin\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    kernel = Kernel()\n",
    "\n",
    "    chat_completion = BedrockChatCompletion(\n",
    "        model_id=os.getenv(\"ANTHROPIC_MODEL_ID\"),\n",
    "    )\n",
    "    kernel.add_service(chat_completion)\n",
    "\n",
    "    setup_logging()\n",
    "    logging.getLogger(\"kernel\").setLevel(logging.INFO)\n",
    "\n",
    "    ## Ready to use plugins - Tavily Web Search\n",
    "    kernel.add_plugin(\n",
    "        TavilySearchPlugin(os.getenv(\"TAVILY_API_KEY\")),\n",
    "        plugin_name=\"TavilyWebSearch\",\n",
    "    )\n",
    "\n",
    "    ## Ready to use plugins - Python Code Generator\n",
    "    execution_settings = BedrockChatPromptExecutionSettings(\n",
    "        max_tokens=4096,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "    python_generator = PythonCodeGeneratorPlugin(\n",
    "        chat_service=chat_completion, execution_settings=execution_settings\n",
    "    )\n",
    "    kernel.add_plugin(python_generator, plugin_name=\"PythonCodeGenerator\")\n",
    "\n",
    "    history = ChatHistory()\n",
    "\n",
    "    userInput = \"Calculate 19! - 465123132\"\n",
    "\n",
    "    history.add_user_message(userInput)\n",
    "    result = await chat_completion.get_chat_message_content(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "    )\n",
    "    print(\"\\033[1m\\033[34mAssistant > \\033[0m\" + str(result))\n",
    "    history.add_message(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:45:48.906] \u001b[32m[INFO] \u001b[0m\n",
      "======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 16:45:48 - PythonCodeGenerator:162 - INFO] [16:45:48.906] \u001b[32m[INFO] \u001b[0m\n",
      "======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:45:48.907] \u001b[32m[INFO] \u001b[0m  INITIALIZING PYTHON CODE GENERATOR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 16:45:48 - PythonCodeGenerator:162 - INFO] [16:45:48.907] \u001b[32m[INFO] \u001b[0m  INITIALIZING PYTHON CODE GENERATOR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:45:48.908] \u001b[32m[INFO] \u001b[0m======================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 16:45:48 - PythonCodeGenerator:162 - INFO] [16:45:48.908] \u001b[32m[INFO] \u001b[0m======================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:45:48.908] \u001b[36m[DEBUG] \u001b[0mCreating Chat Completion Service arn:aws:bedrock:us-east-1:293515758805:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 16:45:48 - PythonCodeGenerator:162 - DEBUG] [16:45:48.908] \u001b[36m[DEBUG] \u001b[0mCreating Chat Completion Service arn:aws:bedrock:us-east-1:293515758805:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating virtual environment at C:\\Users\\samit\\AppData\\Local\\Temp\\sk_python_executor_5x5fqefm\\venv\n",
      "Pip upgraded successfully\n",
      "Virtual environment setup completed\n",
      "[16:45:54.869] \u001b[32m[INFO] \u001b[0mPython Code Generator initialized successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 16:45:54 - PythonCodeGenerator:162 - INFO] [16:45:54.869] \u001b[32m[INFO] \u001b[0mPython Code Generator initialized successfully\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "    except ImportError:\n",
    "        print(\"Please install nest_asyncio: pip install nest_asyncio\")\n",
    "        \n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
